<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>အော်ဒီယို မိုက်ခဲ</title> <!-- Changed title to Burmese -->
    <!-- Tailwind CSS CDN for styling -->
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
    <style>
        /* Define your custom font using @font-face */
        @font-face {
            font-family: 'WaloneBold'; /* Name you'll use in CSS */
            /* Using the raw content URL for the TTF file from your GitHub repo */
            src: url('https://raw.githubusercontent.com/kaungset-git/kaungset-git.github.io/main/js/Z06-Walone%20Bold.ttf') format('truetype');
            font-weight: 700; /* Assuming it's a bold font */
            font-style: normal;
            font-display: swap; /* Ensures text is visible while font loads */
        }

        /* Base styling for the body and container */
        body {
            font-family: 'Inter', sans-serif; /* Inter for general text */
            background-color: #f0f4f8; /* Light gray background */
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh; /* Full viewport height */
            padding: 20px;
            box-sizing: border-box;
        }
        .container {
            background-color: #ffffff; /* White background for the main content area */
            padding: 32px;
            border-radius: 16px; /* Rounded corners */
            box-shadow: 0 10px 25px rgba(0, 0, 0, 0.1); /* Soft shadow for depth */
            width: 100%;
            max-width: 600px; /* Max width for better readability on large screens */
            text-align: center;
        }

        /* Apply the custom font to the main title (h1) */
        h1 {
            font-family: 'WaloneBold', sans-serif; /* Use your custom font, with sans-serif as fallback */
            /* font-weight: 700; is implicitly handled by the @font-face definition for WaloneBold */
        }

        /* Styling for buttons */
        .btn {
            padding: 12px 24px;
            border-radius: 8px;
            font-weight: 600;
            transition: all 0.2s ease-in-out; /* Smooth transitions for hover effects */
            cursor: pointer;
            display: inline-flex;
            align-items: center;
            justify-content: center;
            gap: 8px; /* Space between icon and text */
        }
        .btn-primary {
            background-color: #4f46e5; /* Indigo 600 */
            color: white;
        }
        .btn-primary:hover:not(:disabled) {
            background-color: #4338ca; /* Indigo 700 */
            transform: translateY(-2px); /* Slight lift effect */
            box-shadow: 0 4px 10px rgba(79, 70, 229, 0.3); /* Shadow on hover */
        }
        .btn-danger {
            background-color: #ef4444; /* Red 500 */
            color: white;
        }
        .btn-danger:hover:not(:disabled) {
            background-color: #dc2626; /* Red 600 */
            transform: translateY(-2px);
            box-shadow: 0 4px 10px rgba(239, 68, 68, 0.3);
        }
        .btn-disabled {
            opacity: 0.6; /* Dim disabled buttons */
            cursor: not-allowed;
        }

        /* Styling for message and output boxes */
        .message-box {
            background-color: #fefcbf; /* Light yellow for info/warning */
            border: 1px solid #fcd34d; /* Yellow border */
            color: #92400e; /* Darker yellow text */
            padding: 12px;
            border-radius: 8px;
            margin-top: 20px;
            text-align: left;
            font-size: 0.9em;
        }
        .output-box {
            background-color: #f8fafc; /* Very light blue-gray */
            border: 1px solid #e2e8f0; /* Light gray border */
            padding: 16px;
            border-radius: 8px;
            margin-top: 20px;
            min-height: 100px; /* Minimum height for output area */
            text-align: left;
            white-space: pre-wrap; /* Preserve whitespace and line breaks */
            word-wrap: break-word; /* Break long words to prevent overflow */
        }

        /* Spinner animation for loading states */
        .spinner {
            border: 4px solid rgba(0, 0, 0, 0.1);
            border-left-color: #4f46e5; /* Indigo color for the spinning part */
            border-radius: 50%;
            width: 24px;
            height: 24px;
            animation: spin 1s linear infinite; /* Spin animation */
        }
        @keyframes spin {
            to { transform: rotate(360deg); }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1 class="text-3xl font-bold text-gray-800 mb-6">အော်ဒီယို မိုက်ခဲ</h1> <!-- Changed title to Burmese -->

        <!-- API Key Input Section -->
        <div class="mb-4">
            <label for="apiKey" class="block text-left text-gray-700 text-sm font-medium mb-2">Gemini API Key:</label>
            <input type="password" id="apiKey" placeholder="Enter your Gemini API Key"
                   class="w-full px-4 py-2 border border-gray-300 rounded-lg focus:outline-none focus:ring-2 focus:ring-indigo-500">
            <p class="text-xs text-gray-500 mt-1 text-left">
                Don't have an API key? <a href="https://aistudio.google.com/app/apikey" target="_blank" class="text-indigo-600 hover:underline">Get one here.</a>
            </p>
        </div>

        <!-- Audio Source Selection Section -->
        <div class="mb-6 border border-gray-200 rounded-lg p-4">
            <h2 class="text-xl font-semibold text-gray-700 mb-4 text-left">Choose Audio Source:</h2>
            <div class="flex flex-col sm:flex-row justify-center gap-4 mb-4">
                <!-- Record Audio Button -->
                <button id="toggleRecordingBtn" class="btn btn-primary w-full sm:w-1/2">
                    <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5" viewBox="0 0 20 20" fill="currentColor">
                        <path fill-rule="evenodd" d="M7 4a3 3 0 016 0v4a3 3 0 11-6 0V4zm4 10.93A7.001 7.001 0 0017 8a1 1 0 10-2 0A5 5 0 015 8a1 1 0 00-2 0 7.001 7.001 0 006 6.93V17H6a1 1 0 100 2h8a1 1 0 100-2h-3v-2.07z" clip-rule="evenodd" />
                    </svg>
                    Start Recording
                </button>
                <!-- Upload MP3 File Button (styled as a label for the hidden file input) -->
                <label for="audioFileInput" class="btn btn-primary w-full sm:w-1/2 cursor-pointer">
                    <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5" viewBox="0 0 20 20" fill="currentColor">
                        <path fill-rule="evenodd" d="M.5 9.9a.5.5 0 0 1 .5.5v2.5a.5.5 0 0 0 .5.5h10a.5.5 0 0 0 .5-.5v-2.5a.5.5 0 0 1 1 0v2.5a1.5 1.5 0 0 1-1.5 1.5h-10A1.5 1.5 0 0 1 0 12.9v-2.5a.5.5 0 0 1 .5-.5z" clip-rule="evenodd"/>
                        <path fill-rule="evenodd" d="M7.646 1.146a.5.5 0 0 1 .708 0l3 3a.5.5 0 0 1-.708.708L8.5 2.707V10.5a.5.5 0 0 1-1 0V2.707L5.354 4.854a.5.5 0 1 1-.708-.708l3-3z" clip-rule="evenodd"/>
                    </svg>
                    Upload MP3 File
                    <input type="file" id="audioFileInput" accept="audio/mpeg" class="hidden">
                </label>
            </div>
            <!-- Display for chosen file name -->
            <p id="fileNameDisplay" class="text-sm text-gray-600 mt-2 hidden">No file chosen</p>
        </div>

        <!-- Audio Playback Section (Moved to top of command section) -->
        <div id="audioPlaybackContainer" class="mb-6 hidden">
            <h2 class="text-xl font-semibold text-gray-700 mb-2 text-left">Audio Playback:</h2>
            <audio id="audioPlayback" controls class="w-full rounded-lg"></audio>
        </div>

        <!-- Command/Prompt Input Section -->
        <div class="mb-6">
            <label for="commandInput" class="block text-left text-gray-700 text-sm font-medium mb-2">Command/Prompt:</label>
            <textarea id="commandInput" rows="4" placeholder="e.g., 'Transcribe this audio and summarize the key points.' or 'Analyze the sentiment and extract all mentioned entities.'"
                   class="w-full px-4 py-2 border border-gray-300 rounded-lg focus:outline-none focus:ring-2 focus:ring-indigo-500 resize-y"></textarea>
        </div>

        <!-- Process Audio Button -->
        <button id="processAudioBtn" class="btn btn-primary btn-disabled w-full mb-6" disabled>
            <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5" viewBox="0 0 20 20" fill="currentColor">
                <path fill-rule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z" clip-rule="evenodd" />
            </svg>
            Process Audio
        </button>

        <!-- Status Message Display -->
        <div id="statusMessage" class="message-box hidden"></div>

        <!-- Gemini API Response Section -->
        <div class="mb-6">
            <h2 class="text-xl font-semibold text-gray-700 mb-2 text-left">Gemini API Response:</h2>
            <div id="apiResponse" class="output-box">
                <p class="text-gray-500">Your Gemini API response will appear here after processing.</p>
            </div>
        </div>

        <!-- New: Response Actions Section -->
        <div id="responseActions" class="mb-6 border border-gray-200 rounded-lg p-4 hidden">
            <h2 class="text-xl font-semibold text-gray-700 mb-4 text-left">Response Actions (✨ Gemini LLM):</h2>
            <div class="grid grid-cols-1 md:grid-cols-2 gap-4 mb-4">
                <button id="summarizeResponseBtn" class="btn btn-primary btn-disabled" disabled>
                    <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5" viewBox="0 0 20 20" fill="currentColor">
                        <path fill-rule="evenodd" d="M4 4a2 2 0 00-2 2v8a2 2 0 002 2h12a2 2 0 002-2V6a2 2 0 00-2-2H4zm3 2a1 1 0 00-1 1v2a1 1 0 102 0V7a1 1 0 00-1-1zm5-1a1 1 0 00-1 1v2a1 1 0 102 0V7a1 1 0 00-1-1zM9 9a1 1 0 00-1 1v2a1 1 0 102 0V10a1 1 0 00-1-1z" clip-rule="evenodd" />
                    </svg>
                    Summarize Response ✨
                </button>
                <button id="extractKeyPhrasesBtn" class="btn btn-primary btn-disabled" disabled>
                    <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5" viewBox="0 0 20 20" fill="currentColor">
                        <path fill-rule="evenodd" d="M9.293 2.293a1 1 0 011.414 0l7 7A1 1 0 0117 11h-1a1 1 0 100 2h1a1 1 0 01-1 1h-1a1 1 0 100 2h1a1 1 0 01-1 1H9.293a1 1 0 01-1.414 0l-7-7a1 1 0 010-1.414l7-7zM7 10a1 1 0 11-2 0 1 1 0 012 0zm4 0a1 1 0 11-2 0 1 1 0 012 0zm4 0a1 1 0 11-2 0 1 1 0 012 0z" clip-rule="evenodd" />
                    </svg>
                    Extract Key Phrases ✨
                </button>
                <button id="analyzeSentimentBtn" class="btn btn-primary btn-disabled" disabled>
                    <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5" viewBox="0 0 20 20" fill="currentColor">
                        <path fill-rule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zM7 9a1 1 0 100-2 1 1 0 000 2zm4 0a1 1 0 100-2 1 1 0 000 2zm-3 4a1 1 0 00-1 1v1a1 1 0 002 0v-1a1 1 0 00-1-1z" clip-rule="evenodd" />
                    </svg>
                    Analyze Sentiment ✨
                </button>
                <button id="generateFollowUpQuestionsBtn" class="btn btn-primary btn-disabled" disabled>
                    <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5" viewBox="0 0 20 20" fill="currentColor">
                        <path fill-rule="evenodd" d="M18 10a8 8 0 11-16 0 8 8 0 0116 0zm-7-4a1 1 0 11-2 0 1 1 0 012 0zm-2 2a1 1 0 00-1 1v3a1 1 0 002 0V9a1 1 0 00-1-1zm3 4a1 1 0 00-1 1v1a1 1 0 002 0v-1a1 1 0 00-1-1z" clip-rule="evenodd" />
                    </svg>
                    Generate Follow-up Questions ✨
                </button>
            </div>

            <!-- New: Custom LLM Command Input and Button -->
            <div class="mt-6 pt-4 border-t border-gray-200">
                <label for="llmCommandInput" class="block text-left text-gray-700 text-sm font-medium mb-2">Custom LLM Command:</label>
                <textarea id="llmCommandInput" rows="3" placeholder="e.g., 'Translate this to Spanish' or 'Explain this text simply'"
                       class="w-full px-4 py-2 border border-gray-300 rounded-lg focus:outline-none focus:ring-2 focus:ring-indigo-500 resize-y"></textarea>
                <button id="customLLMProcessBtn" class="btn btn-primary w-full mt-4 btn-disabled" disabled>
                    <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5" viewBox="0 0 20 20" fill="currentColor">
                        <path fill-rule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z" clip-rule="evenodd" />
                    </svg>
                    Process Custom Command ✨
                </button>
            </div>
        </div>

        <!-- Footer Section -->
        <div class="text-center text-gray-500 text-sm mt-8">
            Made with <span style="color: #ef4444;">♥️</span> by <a href="https://www.facebook.com/share/173Qoff4JC/" target="_blank" class="text-indigo-600 hover:underline">@kaungsetzaw</a>
        </div>
    </div>

    <script>
        // Get references to all necessary HTML elements
        const apiKeyInput = document.getElementById('apiKey');
        const commandInput = document.getElementById('commandInput');
        const toggleRecordingBtn = document.getElementById('toggleRecordingBtn');
        const audioFileInput = document.getElementById('audioFileInput');
        const fileNameDisplay = document.getElementById('fileNameDisplay');
        const processAudioBtn = document.getElementById('processAudioBtn');
        const audioPlaybackContainer = document.getElementById('audioPlaybackContainer'); // New reference
        const audioPlayback = document.getElementById('audioPlayback');
        const apiResponseDiv = document.getElementById('apiResponse');
        const statusMessageDiv = document.getElementById('statusMessage');

        // New elements for response actions
        const responseActionsDiv = document.getElementById('responseActions');
        const summarizeResponseBtn = document.getElementById('summarizeResponseBtn');
        const extractKeyPhrasesBtn = document.getElementById('extractKeyPhrasesBtn');
        const analyzeSentimentBtn = document.getElementById('analyzeSentimentBtn');
        const generateFollowUpQuestionsBtn = document.getElementById('generateFollowUpQuestionsBtn');
        const llmCommandInput = document.getElementById('llmCommandInput'); // New custom command textarea
        const customLLMProcessBtn = document.getElementById('customLLMProcessBtn'); // New custom process button

        // Variables to manage recording state and audio data
        let mediaRecorder;
        let audioChunks = [];
        let recordedAudioBlob = null; // Stores the Blob for recorded audio (WebM format)
        let uploadedFileBlob = null;  // Stores the Blob for uploaded MP3 file
        let isRecording = false; // Flag to track recording status
        let originalGeminiResponseText = ''; // Stores the original Gemini API response from audio processing

        /**
         * Displays a status message to the user.
         * @param {string} message - The message to display.
         * @param {'info'|'success'|'error'} type - The type of message (influences styling).
         */
        function showMessage(message, type = 'info') {
            statusMessageDiv.textContent = message;
            // Remove all previous styling classes
            statusMessageDiv.classList.remove('hidden', 'bg-red-100', 'border-red-400', 'text-red-700', 'bg-green-100', 'border-green-400', 'text-green-700', 'bg-yellow-100', 'border-yellow-400', 'text-yellow-700');
            statusMessageDiv.classList.add('block'); // Make sure it's visible

            // Apply specific styling based on message type
            if (type === 'error') {
                statusMessageDiv.classList.add('bg-red-100', 'border-red-400', 'text-red-700');
            } else if (type === 'success') {
                statusMessageDiv.classList.add('bg-green-100', 'border-green-400', 'text-green-700');
            } else { // 'info' or default
                statusMessageDiv.classList.add('bg-yellow-100', 'border-yellow-400', 'text-yellow-700');
            }
        }

        /**
         * Hides the status message.
         */
        function hideMessage() {
            statusMessageDiv.classList.add('hidden');
        }

        /**
         * Converts an Audio Blob to a Base64 string.
         * This is required for sending binary audio data to the Gemini API via inlineData.
         * @param {Blob} blob - The audio Blob to convert.
         * @returns {Promise<string>} A promise that resolves with the Base64 string.
         */
        function blobToBase64(blob) {
            return new Promise((resolve, reject) => {
                const reader = new FileReader();
                reader.onloadend = () => {
                    // The result includes a data URL prefix (e.g., "data:audio/webm;base64,").
                    // We only need the Base64 part, so we split by ',' and take the second element.
                    const base64String = reader.result.split(',')[1];
                    resolve(base64String);
                };
                reader.onerror = reject; // Handle potential errors during file reading
                reader.readAsDataURL(blob); // Read the Blob as a data URL
            });
        }

        /**
         * Resets all audio-related states and UI elements.
         * This function is called when a new audio source is selected (either recording or uploading).
         */
        function resetAudioSources() {
            recordedAudioBlob = null; // Clear recorded audio
            uploadedFileBlob = null;  // Clear uploaded audio
            audioChunks = [];         // Clear recording chunks
            audioPlayback.src = '';   // Clear audio playback source
            fileNameDisplay.textContent = 'No file chosen'; // Reset file name display
            fileNameDisplay.classList.add('hidden'); // Hide file name display
            audioPlaybackContainer.classList.add('hidden'); // Hide audio playback container
            // Reset API response area
            apiResponseDiv.innerHTML = '<p class="text-gray-500">Your Gemini API response will appear here after processing.</p>';
            originalGeminiResponseText = ''; // New: Clear the stored original response
            // Disable process button until new audio is ready
            processAudioBtn.disabled = true;
            processAudioBtn.classList.add('btn-disabled');
            hideMessage(); // Clear any existing status messages
            updateResponseActionButtonsState(); // Update state of new buttons
        }

        /**
         * Updates the enabled/disabled state of the response action buttons
         * based on whether there is content in the originalGeminiResponseText.
         */
        function updateResponseActionButtonsState() {
            // Check if originalGeminiResponseText has content
            const hasOriginalResponseContent = originalGeminiResponseText.trim() !== '';

            if (hasOriginalResponseContent) {
                responseActionsDiv.classList.remove('hidden');
                summarizeResponseBtn.disabled = false;
                summarizeResponseBtn.classList.remove('btn-disabled');
                extractKeyPhrasesBtn.disabled = false;
                extractKeyPhrasesBtn.classList.remove('btn-disabled');
                analyzeSentimentBtn.disabled = false;
                analyzeSentimentBtn.classList.remove('btn-disabled');
                generateFollowUpQuestionsBtn.disabled = false;
                generateFollowUpQuestionsBtn.classList.remove('btn-disabled');
                llmCommandInput.disabled = false; // Enable custom LLM command input
                customLLMProcessBtn.disabled = false; // Enable custom LLM process button
                customLLMProcessBtn.classList.remove('btn-disabled');
            } else {
                responseActionsDiv.classList.add('hidden');
                summarizeResponseBtn.disabled = true;
                summarizeResponseBtn.classList.add('btn-disabled');
                extractKeyPhrasesBtn.disabled = true;
                extractKeyPhrasesBtn.classList.add('btn-disabled');
                analyzeSentimentBtn.disabled = true;
                analyzeSentimentBtn.classList.add('btn-disabled');
                generateFollowUpQuestionsBtn.disabled = true;
                generateFollowUpQuestionsBtn.classList.add('btn-disabled');
                llmCommandInput.disabled = true; // Disable custom LLM command input
                customLLMProcessBtn.disabled = true; // Disable custom LLM process button
                customLLMProcessBtn.classList.add('btn-disabled');
            }
        }

        /**
         * Event listener for the single "Start/Stop Recording" button.
         * Toggles between starting and stopping audio recording.
         */
        toggleRecordingBtn.addEventListener('click', async () => {
            if (!isRecording) {
                // --- Start Recording Logic ---
                resetAudioSources(); // Clear any previously loaded or recorded audio

                try {
                    // Request access to the user's microphone
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    mediaRecorder = new MediaRecorder(stream); // Initialize MediaRecorder with the audio stream

                    // Event handler for when audio data is available (chunks are periodically emitted)
                    mediaRecorder.ondataavailable = (event) => {
                        audioChunks.push(event.data); // Collect audio data chunks
                    };

                    // Event handler for when recording stops
                    mediaRecorder.onstop = () => {
                        // Create a Blob from the collected audio chunks
                        recordedAudioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                        // Create a URL for the Blob to set as the audio playback source
                        const audioUrl = URL.createObjectURL(recordedAudioBlob);
                        audioPlayback.src = audioUrl;

                        audioPlaybackContainer.classList.remove('hidden'); // Show audio playback container
                        showMessage('Recording stopped. Audio ready for processing.', 'info');
                        // Enable the process button as audio is now available
                        processAudioBtn.disabled = false;
                        processAudioBtn.classList.remove('btn-disabled');

                        // Stop all tracks in the stream to release the microphone
                        mediaRecorder.stream.getTracks().forEach(track => track.stop());
                    };

                    mediaRecorder.start(); // Start the recording
                    isRecording = true; // Update recording state
                    toggleRecordingBtn.textContent = 'Stop Recording'; // Change button text
                    toggleRecordingBtn.classList.remove('btn-primary'); // Change button color to danger
                    toggleRecordingBtn.classList.add('btn-danger');
                    audioFileInput.disabled = true; // Disable file input while recording
                    fileNameDisplay.classList.add('hidden'); // Hide file name display
                    audioPlaybackContainer.classList.add('hidden'); // Hide audio playback container during recording
                    showMessage('Recording started...', 'info');

                } catch (error) {
                    console.error('Error accessing microphone:', error);
                    showMessage('Error accessing microphone. Please ensure you grant permission and try again.', 'error');
                    isRecording = false; // Reset recording state on error
                    toggleRecordingBtn.textContent = 'Start Recording'; // Reset button text
                    toggleRecordingBtn.classList.remove('btn-danger');
                    toggleRecordingBtn.classList.add('btn-primary');
                    audioFileInput.disabled = false; // Re-enable file input
                    processAudioBtn.disabled = true; // Ensure process button is disabled on error
                    processAudioBtn.classList.add('btn-disabled');
                    audioPlaybackContainer.classList.add('hidden'); // Ensure hidden on error
                }
            } else {
                // --- Stop Recording Logic ---
                if (mediaRecorder && mediaRecorder.state === 'recording') {
                    mediaRecorder.stop(); // Stop the recording
                }
                isRecording = false; // Update recording state
                toggleRecordingBtn.textContent = 'Start Recording'; // Reset button text
                toggleRecordingBtn.classList.remove('btn-danger');
                toggleRecordingBtn.classList.add('btn-primary');
                audioFileInput.disabled = false; // Re-enable file input after stopping recording
            }
        });

        /**
         * Event listener for the "Upload MP3 File" input.
         * Handles the selection and loading of an MP3 file.
         */
        audioFileInput.addEventListener('change', (event) => {
            resetAudioSources(); // Clear any previously loaded or recorded audio

            const file = event.target.files[0]; // Get the selected file
            if (file) {
                if (file.type === 'audio/mpeg') { // Check if the file is an MP3
                    uploadedFileBlob = file; // Store the uploaded file Blob
                    const audioUrl = URL.createObjectURL(uploadedFileBlob);
                    audioPlayback.src = audioUrl; // Set audio playback source
                    fileNameDisplay.textContent = `Selected: ${file.name}`; // Display file name
                    fileNameDisplay.classList.remove('hidden'); // Make file name display visible
                    audioPlaybackContainer.classList.remove('hidden'); // Show audio playback container
                    showMessage('MP3 file selected. Ready for processing.', 'info');
                    processAudioBtn.disabled = false; // Enable process button
                    processAudioBtn.classList.remove('btn-disabled');

                    // If recording was active, stop it to prevent conflicts
                    if (isRecording && mediaRecorder && mediaRecorder.state === 'recording') {
                        mediaRecorder.stop();
                        isRecording = false;
                        toggleRecordingBtn.textContent = 'Start Recording';
                        toggleRecordingBtn.classList.remove('btn-danger');
                        toggleRecordingBtn.classList.add('btn-primary');
                    }
                    toggleRecordingBtn.disabled = true; // Disable record button when a file is selected
                    toggleRecordingBtn.classList.add('btn-disabled');

                } else {
                    // Handle non-MP3 files
                    showMessage('Please upload an MP3 file (audio/mpeg). Other formats are not supported for upload.', 'error');
                    uploadedFileBlob = null; // Clear invalid file
                    audioFileInput.value = ''; // Clear the file input to allow re-selection
                    fileNameDisplay.textContent = 'No file chosen';
                    fileNameDisplay.classList.add('hidden');
                    audioPlaybackContainer.classList.add('hidden'); // Hide audio playback container on invalid file
                    processAudioBtn.disabled = true;
                    processAudioBtn.classList.add('btn-disabled');
                    toggleRecordingBtn.disabled = false; // Re-enable if invalid file
                    toggleRecordingBtn.classList.remove('btn-disabled');
                }
            } else {
                // If no file was selected (e.g., user opened dialog and cancelled)
                fileNameDisplay.textContent = 'No file chosen';
                fileNameDisplay.classList.add('hidden');
                uploadedFileBlob = null;
                audioPlaybackContainer.classList.add('hidden'); // Hide audio playback container if no file selected
                processAudioBtn.disabled = true;
                processAudioBtn.classList.add('btn-disabled');
                showMessage('No file selected.', 'info');
                toggleRecordingBtn.disabled = false; // Re-enable record button if no file selected
                toggleRecordingBtn.classList.remove('btn-disabled');
            }
        });

        // Event listener for Process Audio button
        processAudioBtn.addEventListener('click', async () => {
            await sendAudioToGemini();
        });

        /**
         * Sends the current audio (recorded or uploaded) and command to the Gemini API.
         */
        async function sendAudioToGemini() {
            const apiKey = apiKeyInput.value.trim();
            if (!apiKey) {
                showMessage('Please enter your Gemini API Key before processing.', 'error');
                return;
            }

            let audioBlobToSend = null;
            let mimeType = '';

            // Determine which audio source to use
            if (recordedAudioBlob) {
                audioBlobToSend = recordedAudioBlob;
                mimeType = 'audio/webm'; // Mime type for recorded audio
            } else if (uploadedFileBlob) {
                audioBlobToSend = uploadedFileBlob;
                mimeType = 'audio/mpeg'; // Mime type for MP3 files
            } else {
                // If neither recorded nor uploaded audio is available
                showMessage('No audio to process. Please record or upload an audio file first.', 'error');
                return;
            }

            const commandText = commandInput.value.trim();
            if (!commandText) {
                showMessage('Please enter a command/prompt for the audio analysis.', 'error');
                return;
            }

            showMessage('Sending audio to Gemini API...', 'info');
            // Display a loading spinner and message
            apiResponseDiv.innerHTML = '<div class="spinner mx-auto"></div><p class="text-gray-500 mt-2">Analyzing audio with command...</p>';
            
            // Disable interaction during API call
            processAudioBtn.disabled = true;
            processAudioBtn.classList.add('btn-disabled');
            toggleRecordingBtn.disabled = true;
            toggleRecordingBtn.classList.add('btn-disabled');
            audioFileInput.disabled = true;
            updateResponseActionButtonsState(); // Disable response action buttons during processing

            try {
                // Convert the active audio Blob to Base64
                const base64Audio = await blobToBase64(audioBlobToSend);

                // Construct the chat history payload for the Gemini API
                const chatHistory = [];
                chatHistory.push({
                    role: "user",
                    parts: [
                        { text: commandText }, // The user's command as the text prompt
                        {
                            inlineData: {
                                mimeType: mimeType, // Dynamic MIME type based on audio source
                                data: base64Audio
                            }
                        }
                    ]
                });

                const payload = { contents: chatHistory };
                // The API key is dynamically provided by the Canvas environment if left empty.
                const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${apiKey}`;

                // Make the API call to Gemini
                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });

                const result = await response.json(); // Parse the JSON response

                // Process the API response
                if (result.candidates && result.candidates.length > 0 &&
                    result.candidates[0].content && result.candidates[0].content.parts &&
                    result.candidates[0].content.parts.length > 0) {
                    const text = result.candidates[0].content.parts[0].text;
                    apiResponseDiv.textContent = text; // Display the Gemini's response
                    originalGeminiResponseText = text; // Store the original response text
                    showMessage('Response received from Gemini API.', 'success');
                } else if (result.error) {
                    // Handle API errors
                    apiResponseDiv.textContent = `Error: ${result.error.message}`;
                    showMessage(`API Error: ${result.error.message}`, 'error');
                } else {
                    // Handle unexpected response structures
                    apiResponseDiv.textContent = 'Unexpected API response structure. Please check the console for details.';
                    showMessage('Unexpected API response.', 'error');
                }
            } catch (error) {
                // Handle network or other fetch-related errors
                console.error('Error calling Gemini API:', error);
                apiResponseDiv.textContent = `Failed to connect to Gemini API: ${error.message}`;
                showMessage(`Failed to connect to Gemini API: ${error.message}`, 'error');
            } finally {
                // Always re-enable buttons after the API call completes (success or failure)
                processAudioBtn.disabled = false;
                processAudioBtn.classList.remove('btn-disabled');
                // Only re-enable toggleRecordingBtn if no file is currently selected
                if (!uploadedFileBlob) {
                    toggleRecordingBtn.disabled = false;
                    toggleRecordingBtn.classList.remove('btn-disabled');
                }
                audioFileInput.disabled = false; // Re-enable file input
                updateResponseActionButtonsState(); // Re-enable response action buttons based on content
            }
        }

        /**
         * Sends the original response text to Gemini for summarization.
         */
        summarizeResponseBtn.addEventListener('click', async () => {
            const textToProcess = originalGeminiResponseText; // Use the stored original text
            if (!textToProcess) {
                showMessage('No original response to summarize. Please process audio first.', 'error');
                return;
            }

            const apiKey = apiKeyInput.value.trim();
            if (!apiKey) {
                showMessage('Please enter your Gemini API Key.', 'error');
                return;
            }

            showMessage('Summarizing response with Gemini API...', 'info');
            apiResponseDiv.innerHTML = '<div class="spinner mx-auto"></div><p class="text-gray-500 mt-2">Summarizing...</p>';
            
            // Disable all action buttons during this new API call
            processAudioBtn.disabled = true; processAudioBtn.classList.add('btn-disabled');
            toggleRecordingBtn.disabled = true; toggleRecordingBtn.classList.add('btn-disabled');
            audioFileInput.disabled = true;
            updateResponseActionButtonsState(); // Ensure LLM action buttons are disabled

            try {
                const chatHistory = [];
                chatHistory.push({
                    role: "user",
                    parts: [{ text: `Summarize the following text concisely:\n\n${textToProcess}` }]
                });

                const payload = { contents: chatHistory };
                const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${apiKey}`;

                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });

                const result = await response.json();

                if (result.candidates && result.candidates.length > 0 &&
                    result.candidates[0].content && result.candidates[0].content.parts &&
                    result.candidates[0].content.parts.length > 0) {
                    const text = result.candidates[0].content.parts[0].text;
                    apiResponseDiv.textContent = text;
                    showMessage('Response summarized by Gemini API.', 'success');
                } else if (result.error) {
                    apiResponseDiv.textContent = `Error summarizing: ${result.error.message}`;
                    showMessage(`API Error summarizing: ${result.error.message}`, 'error');
                } else {
                    apiResponseDiv.textContent = 'Unexpected API response structure during summarization.';
                    showMessage('Unexpected API response during summarization.', 'error');
                }
            } catch (error) {
                console.error('Error calling Gemini API for summarization:', error);
                apiResponseDiv.textContent = `Failed to summarize response: ${error.message}`;
                showMessage(`Failed to summarize response: ${error.message}`, 'error');
            } finally {
                // Re-enable buttons
                processAudioBtn.disabled = false; processAudioBtn.classList.remove('btn-disabled');
                if (!uploadedFileBlob) { // Only re-enable record button if no file is selected
                    toggleRecordingBtn.disabled = false; toggleRecordingBtn.classList.remove('btn-disabled');
                }
                audioFileInput.disabled = false;
                updateResponseActionButtonsState(); // Re-enable LLM action buttons based on new content
            }
        });

        /**
         * Sends the original response text to Gemini for key phrase extraction.
         */
        extractKeyPhrasesBtn.addEventListener('click', async () => {
            const textToProcess = originalGeminiResponseText; // Use the stored original text
            if (!textToProcess) {
                showMessage('No original response to extract key phrases from. Please process audio first.', 'error');
                return;
            }

            const apiKey = apiKeyInput.value.trim();
            if (!apiKey) {
                showMessage('Please enter your Gemini API Key.', 'error');
                return;
            }

            showMessage('Extracting key phrases with Gemini API...', 'info');
            apiResponseDiv.innerHTML = '<div class="spinner mx-auto"></div><p class="text-gray-500 mt-2">Extracting key phrases...</p>';
            
            // Disable all action buttons during this new API call
            processAudioBtn.disabled = true; processAudioBtn.classList.add('btn-disabled');
            toggleRecordingBtn.disabled = true; toggleRecordingBtn.classList.add('btn-disabled');
            audioFileInput.disabled = true;
            updateResponseActionButtonsState(); // Ensure LLM action buttons are disabled

            try {
                const chatHistory = [];
                chatHistory.push({
                    role: "user",
                    parts: [{ text: `Extract the most important keywords and phrases from the following text, separated by commas:\n\n${textToProcess}` }]
                });

                const payload = { contents: chatHistory };
                const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${apiKey}`;

                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });

                const result = await response.json();

                if (result.candidates && result.candidates.length > 0 &&
                    result.candidates[0].content && result.candidates[0].content.parts &&
                    result.candidates[0].content.parts.length > 0) {
                    const text = result.candidates[0].content.parts[0].text;
                    apiResponseDiv.textContent = text;
                    showMessage('Key phrases extracted by Gemini API.', 'success');
                } else if (result.error) {
                    apiResponseDiv.textContent = `Error extracting key phrases: ${result.error.message}`;
                    showMessage(`API Error extracting key phrases: ${result.error.message}`, 'error');
                } else {
                    apiResponseDiv.textContent = 'Unexpected API response structure during key phrase extraction.';
                    showMessage('Unexpected API response during key phrase extraction.', 'error');
                }
            } catch (error) {
                console.error('Error calling Gemini API for key phrase extraction:', error);
                apiResponseDiv.textContent = `Failed to extract key phrases: ${error.message}`;
                showMessage(`Failed to extract key phrases: ${error.message}`, 'error');
            } finally {
                // Re-enable buttons
                processAudioBtn.disabled = false; processAudioBtn.classList.remove('btn-disabled');
                if (!uploadedFileBlob) { // Only re-enable record button if no file is selected
                    toggleRecordingBtn.disabled = false; toggleRecordingBtn.classList.remove('btn-disabled');
                }
                audioFileInput.disabled = false;
                updateResponseActionButtonsState(); // Re-enable LLM action buttons based on new content
            }
        });

        /**
         * Sends the original response text to Gemini for sentiment analysis.
         */
        analyzeSentimentBtn.addEventListener('click', async () => {
            const textToProcess = originalGeminiResponseText; // Use the stored original text
            if (!textToProcess) {
                showMessage('No original response to analyze sentiment for. Please process audio first.', 'error');
                return;
            }

            const apiKey = apiKeyInput.value.trim();
            if (!apiKey) {
                showMessage('Please enter your Gemini API Key.', 'error');
                return;
            }

            showMessage('Analyzing sentiment with Gemini API...', 'info');
            apiResponseDiv.innerHTML = '<div class="spinner mx-auto"></div><p class="text-gray-500 mt-2">Analyzing sentiment...</p>';
            
            // Disable all action buttons during this new API call
            processAudioBtn.disabled = true; processAudioBtn.classList.add('btn-disabled');
            toggleRecordingBtn.disabled = true; toggleRecordingBtn.classList.add('btn-disabled');
            audioFileInput.disabled = true;
            updateResponseActionButtonsState(); // Ensure LLM action buttons are disabled

            try {
                const chatHistory = [];
                chatHistory.push({
                    role: "user",
                    parts: [{ text: `Analyze the sentiment of the following text (e.g., positive, negative, neutral, mixed). Provide a brief explanation:\n\n${textToProcess}` }]
                });

                const payload = { contents: chatHistory };
                const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${apiKey}`;

                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });

                const result = await response.json();

                if (result.candidates && result.candidates.length > 0 &&
                    result.candidates[0].content && result.candidates[0].content.parts &&
                    result.candidates[0].content.parts.length > 0) {
                    const text = result.candidates[0].content.parts[0].text;
                    apiResponseDiv.textContent = text;
                    showMessage('Sentiment analyzed by Gemini API.', 'success');
                } else if (result.error) {
                    apiResponseDiv.textContent = `Error analyzing sentiment: ${result.error.message}`;
                    showMessage(`API Error analyzing sentiment: ${result.error.message}`, 'error');
                } else {
                    apiResponseDiv.textContent = 'Unexpected API response structure during sentiment analysis.';
                    showMessage('Unexpected API response during sentiment analysis.', 'error');
                }
            } catch (error) {
                console.error('Error calling Gemini API for sentiment analysis:', error);
                apiResponseDiv.textContent = `Failed to analyze sentiment: ${error.message}`;
                showMessage(`Failed to analyze sentiment: ${error.message}`, 'error');
            } finally {
                // Re-enable buttons
                processAudioBtn.disabled = false; processAudioBtn.classList.remove('btn-disabled');
                if (!uploadedFileBlob) { // Only re-enable record button if no file is selected
                    toggleRecordingBtn.disabled = false; toggleRecordingBtn.classList.remove('btn-disabled');
                }
                audioFileInput.disabled = false;
                updateResponseActionButtonsState(); // Re-enable LLM action buttons based on new content
            }
        });

        /**
         * Sends the original response text to Gemini to generate follow-up questions.
         */
        generateFollowUpQuestionsBtn.addEventListener('click', async () => {
            const textToProcess = originalGeminiResponseText; // Use the stored original text
            if (!textToProcess) {
                showMessage('No original response to generate follow-up questions for. Please process audio first.', 'error');
                return;
            }

            const apiKey = apiKeyInput.value.trim();
            if (!apiKey) {
                showMessage('Please enter your Gemini API Key.', 'error');
                return;
            }

            showMessage('Generating follow-up questions with Gemini API...', 'info');
            apiResponseDiv.innerHTML = '<div class="spinner mx-auto"></div><p class="text-gray-500 mt-2">Generating questions...</p>';
            
            // Disable all action buttons during this new API call
            processAudioBtn.disabled = true; processAudioBtn.classList.add('btn-disabled');
            toggleRecordingBtn.disabled = true; toggleRecordingBtn.classList.add('btn-disabled');
            audioFileInput.disabled = true;
            updateResponseActionButtonsState(); // Ensure LLM action buttons are disabled

            try {
                const chatHistory = [];
                chatHistory.push({
                    role: "user",
                    parts: [{ text: `Based on the following text, generate 2-3 relevant and insightful follow-up questions:\n\n${textToProcess}` }]
                });

                const payload = { contents: chatHistory };
                const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${apiKey}`;

                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });

                const result = await response.json();

                if (result.candidates && result.candidates.length > 0 &&
                    result.candidates[0].content && result.candidates[0].content.parts &&
                    result.candidates[0].content.parts.length > 0) {
                    const text = result.candidates[0].content.parts[0].text;
                    apiResponseDiv.textContent = text;
                    showMessage('Follow-up questions generated by Gemini API.', 'success');
                } else if (result.error) {
                    apiResponseDiv.textContent = `Error generating questions: ${result.error.message}`;
                    showMessage(`API Error generating questions: ${result.error.message}`, 'error');
                } else {
                    apiResponseDiv.textContent = 'Unexpected API response structure during question generation.';
                    showMessage('Unexpected API response during question generation.', 'error');
                }
            } catch (error) {
                console.error('Error calling Gemini API for question generation:', error);
                apiResponseDiv.textContent = `Failed to generate questions: ${error.message}`;
                showMessage(`Failed to generate questions: ${error.message}`, 'error');
            } finally {
                // Re-enable buttons
                processAudioBtn.disabled = false; processAudioBtn.classList.remove('btn-disabled');
                if (!uploadedFileBlob) { // Only re-enable record button if no file is selected
                    toggleRecordingBtn.disabled = false; toggleRecordingBtn.classList.remove('btn-disabled');
                }
                audioFileInput.disabled = false;
                updateResponseActionButtonsState(); // Re-enable LLM action buttons based on new content
            }
        });

        /**
         * Sends the original response text and a custom command to Gemini.
         */
        customLLMProcessBtn.addEventListener('click', async () => {
            const textToProcess = originalGeminiResponseText; // Use the stored original text
            const customCommand = llmCommandInput.value.trim();

            if (!textToProcess) {
                showMessage('No original response to process with custom command. Please process audio first.', 'error');
                return;
            }
            if (!customCommand) {
                showMessage('Please enter a custom command for the LLM.', 'error');
                return;
            }

            const apiKey = apiKeyInput.value.trim();
            if (!apiKey) {
                showMessage('Please enter your Gemini API Key.', 'error');
                return;
            }

            showMessage('Processing custom command with Gemini API...', 'info');
            apiResponseDiv.innerHTML = '<div class="spinner mx-auto"></div><p class="text-gray-500 mt-2">Processing custom command...</p>';
            
            // Disable all action buttons during this new API call
            processAudioBtn.disabled = true; processAudioBtn.classList.add('btn-disabled');
            toggleRecordingBtn.disabled = true; toggleRecordingBtn.classList.add('btn-disabled');
            audioFileInput.disabled = true;
            updateResponseActionButtonsState(); // Ensure LLM action buttons are disabled

            try {
                const chatHistory = [];
                chatHistory.push({
                    role: "user",
                    parts: [{ text: `${customCommand}\n\nText to process: ${textToProcess}` }]
                });

                const payload = { contents: chatHistory };
                const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${apiKey}`;

                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });

                const result = await response.json();

                if (result.candidates && result.candidates.length > 0 &&
                    result.candidates[0].content && result.candidates[0].content.parts &&
                    result.candidates[0].content.parts.length > 0) {
                    const text = result.candidates[0].content.parts[0].text;
                    apiResponseDiv.textContent = text;
                    showMessage('Custom command processed by Gemini API.', 'success');
                } else if (result.error) {
                    apiResponseDiv.textContent = `Error processing custom command: ${result.error.message}`;
                    showMessage(`API Error processing custom command: ${result.error.message}`, 'error');
                } else {
                    apiResponseDiv.textContent = 'Unexpected API response structure during custom command processing.';
                    showMessage('Unexpected API response during custom command processing.', 'error');
                }
            } catch (error) {
                console.error('Error calling Gemini API for custom command:', error);
                apiResponseDiv.textContent = `Failed to process custom command: ${error.message}`;
                showMessage(`Failed to process custom command: ${error.message}`, 'error');
            } finally {
                // Re-enable buttons
                processAudioBtn.disabled = false; processAudioBtn.classList.remove('btn-disabled');
                if (!uploadedFileBlob) { // Only re-enable record button if no file is selected
                    toggleRecordingBtn.disabled = false; toggleRecordingBtn.classList.remove('btn-disabled');
                }
                audioFileInput.disabled = false;
                updateResponseActionButtonsState(); // Re-enable LLM action buttons based on new content
            }
        });


        // Initial state update for response action buttons
        updateResponseActionButtonsState();
    </script>
</body>
</html>
